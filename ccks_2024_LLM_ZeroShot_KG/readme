复现
pip install -r requirements.txt
1. 下载Qwen2-72B-instruct-AWQ
2. python offline_batch.py
输入：data/ccks2024复赛.json
输出：data/qwen2-72B-final.json



# 调参文档
https://c740uhpr2i.feishu.cn/sheets/B7CFs8ijih1c9xtqKLAcL6FdnVg?sheet=pasm3e
参数很重要

#Qwen2-7B-instruct-awq
1. 作品不能带书名号,F1 50->57
2. output 与schema 完全对齐，删除无关输出,JSON异常只有3 56->59

3. 有几个品类的作品也需要进行整理《》；二层字典的key。 59->61.4
4. 个性化source example： 61.4->60; 应该是有些prompt不适合,或者更简单了,
    法律：有很多模糊地方（比如实施日期，颁发日期），不知道如何抽取
	很有意思：即使只保留：default,区域，场所，词汇，饮食, 61.4 -> 61.0
	delete 词汇demo 61->61.2
	reback


# UniNER-7B-all：26G  似乎应该用:UniNER-7B-definition  对于示意改写更兼容
1. Llama + ChatGPT生成的数据 -> 英文友好，中文估计支持不行; 耗时从2min-》12min左右；还能run起来
如果全面微调中文，成本太高。 
2. Instruction 和预训练不一致。
需要先生成实体，然后 实体+属性，生成每一个属性值 才比较适配
先delay

# Qwen2-72B-awq
1. 慢慢下载; 分片段 GIT_LFS_SKIP_SMUDGE=1 git clone https://www.modelscope.cn/qwen/Qwen2-72B-Instruct-AWQ.git  直接git clone : 一直不成功,被killed
2. git lfs pull --include=model-00004-of-00011.safetensors

同样的代码:显卡OOM
61.4->65.3
# badcase 分析
1. 菜品中：辅材，主材，调味品区分度不够； 隐藏的制作工艺没有提取出来

# OneKE探索

# SFT
1. 数据,以哪个作为基准呢?
2. 仔细查看数据:shcema 似乎有不合理的地方,与input不配对,这种情况问题很大

# 数据集
## IEPile
NER,RE,EE类型; 尤其是RE,三元组对语义理解有一定帮助,但是又和比赛有一定差异性
InstructIE: 是可以转换成本次比赛的格式的数据; 官方说有一定的噪音,那么就需要对数据进行提纯

TODO
1. 观察InstructIE ,产生微调数据集.调试了几轮，没有效果，反而下降


# 思考
比赛数据：很依赖entity, attribute的描述信息，比如：调味品，辅材，主材，烹饪方式等也与对应的description 有极大的关系
对应的InstructIE 问题是：属性词缺乏描述信息，比较单吊，缺乏语义变化后的结果对比




# CCKS复赛数据
entities:131
	'政治人物': 120,
	'历史人物': 65,
	'公司': 49,
	'法律法规': 48,
	'文化人物': 40,
	'汽车': 41,
	'运动员': 29,
摸底头部entities主要问题
1. 
attributes:578
